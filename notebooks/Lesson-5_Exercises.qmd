---
title: "Tema 5: Ejercicio"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
---

# Introducci√≥n

En este tema hemos estudiado el m√©todo de Monte Carlo.
Ahora vamos a ponerlo en pr√°ctica, comparando sus resultados con lo que ya conocemos de temas anteriores.
En esta ocasi√≥n, la entrega consiste en un ejercicio sobre el modelo normal-normal, y otro sobre el modelo Poisson-Gamma.

Al igual que en el Tema 3, configuramos primero el entorno.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)


# Configuraci√≥n de la salida gr√°fica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto  <- PALETA[1]
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representaci√≥n gr√°fica

# Redondea los n√∫meros reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)
```

# Ejercicio 1: Modelo normal-normal

## Ajuste de modelos

En este ejercicio vamos a utilizar nuevamente el modelo normal-normal del [Ejercicio 4 del Tema 3](https://github.com/DV-Morillo/Ejercicios-ABD/blob/main/notebooks/Lesson-3_Exercises.qmd#L382).

Aqu√≠ tienes nuevamente los datos:

```{r normal-normal-muestras}
# Tiempo en s para leer un texto est√°ndar en una prueba de lectura de las 2
#   clases de 1¬∫ de ESO en un colegio:
clase_1 <- tibble(
  id     = 1:27,
  tiempo = c(
    242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
    228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
    168, 250
  )
)

clase_2 <- tibble(
  id     = 1:24,
  tiempo = c(
    195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
    144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282
  )
)
```

Los datos de la distribuci√≥n previa eran los datos de la poblaci√≥n.
Recuerda:

```{r normal-normal-previa-params}
MU_PREVIA     <- 247
SIGMA2_PREVIA <-  34^2
```

Aplicando la propiedad de conjugaci√≥n, recuerda que podemos obtener la expresi√≥n anal√≠tica de la distribuci√≥n posterior de la media:

$p(\mu | y) = N(\mu_{post}, \sigma^2_{post})$,

siendo

$$
\mu\_{post} = \frac{\sigma^2_y \mu_{pre} + n \sigma^2_{pre} \bar{y}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

y

$$
\sigma^2\_{post} = \frac{\sigma^2_y \sigma^2_{pre}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

### Pregunta 1

-   Utilizando la expresi√≥n anal√≠tica del modelo, obt√©n la expresi√≥n anal√≠tica de la distribuci√≥n posterior de la media para cada una de las dos clases, con 2 decimales.

::: {#respuesta-1 .callout-note}

#Estad√≠sticos muestrales de cada clase 
```{r}
resumen <- bind_rows(
  clase_1 %>% summarise(
    clase = "clase_1",
    n = n(),
    media = mean(tiempo),
    varianza = var(tiempo)
  ),
  clase_2 %>% summarise(
    clase = "clase_2",
    n = n(),
    media = mean(tiempo),
    varianza = var(tiempo)
  )
)

resumen
```


RESPUESTA 

clase       n media varianza
  <chr>   <int> <dbl>    <dbl>
1 clase_1    27  234     2073.
2 clase_2    24  221.    1695.

#Par√°metros de la distribuci√≥n posterior

# Par√°metros de la distribuci√≥n previa

```{r}
MU_PREVIA     <- 247
SIGMA2_PREVIA <- 34^2
```

# Distribuci√≥n posterior para Clase 1
```{r}
mu_post_1     <- (resumen$varianza[1] * MU_PREVIA + resumen$n[1] * SIGMA2_PREVIA * resumen$media[1]) /
                 (resumen$varianza[1] + resumen$n[1] * SIGMA2_PREVIA)

sigma2_post_1 <- (resumen$varianza[1] * SIGMA2_PREVIA) /
                 (resumen$varianza[1] + resumen$n[1] * SIGMA2_PREVIA)
```


# Distribuci√≥n posterior para Clase 2
```{r}
mu_post_2     <- (resumen$varianza[2] * MU_PREVIA + resumen$n[2] * SIGMA2_PREVIA * resumen$media[2]) /
                 (resumen$varianza[2] + resumen$n[2] * SIGMA2_PREVIA)

sigma2_post_2 <- (resumen$varianza[2] * SIGMA2_PREVIA) /
                 (resumen$varianza[2] + resumen$n[2] * SIGMA2_PREVIA)

```

# Resultados
```{r}
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Mu_post = c(mu_post_1, mu_post_2),
  Sigma2_post = c(sigma2_post_1, sigma2_post_2)
)
```


RESPUESTA 

Clase Mu_post Sigma2_post
1 Clase 1  234.81      71.984
2 Clase 2  222.34      66.553

:::

## Simulaci√≥n de Monte Carlo

Para cada familia de distribuciones de probabilidad existe la funci√≥n `r*()` en R que permite simular valores de esa distribuci√≥n.
Por ejemplo, en el caso de la normal, `rnorm(10, mean = 1, sd = 0)` extrae 10 muestras "independientes e igualmente distribuidas" de una distribuci√≥n normal est√°ndar.

### Pregunta 2

-   Para cada una de las dos clases, extrae 500 muestras de la distribuci√≥n posterior.

*(Recomendaci√≥n: Inicializa la "semilla aleatoria" para evitar tener valores diferentes en cada ejecuci√≥n)*

```{r inicializa-semilla}
set.seed(20250318)
```

::: {#respuesta-2 .callout-note}

```{r}
# Inicializaci√≥n de la semilla para asegurar la reproducibilidad
set.seed(20250318)

# Extraer 500 muestras para cada clase de su distribuci√≥n posterior
muestras_clase_1 <- rnorm(500, mean = mu_post_1, sd = sqrt(sigma2_post_1))
muestras_clase_2 <- rnorm(500, mean = mu_post_2, sd = sqrt(sigma2_post_2))

# Ver los primeros resultados de las muestras generadas
head(muestras_clase_1)
head(muestras_clase_2)
```


RESPUESTA PRIMEROS RESULTADOS GENERADOS 

CLASE 1: 
214.51 240.04 240.37 230.34 230.39 227.97

ClASE 2:
224.03 222.57 227.19 230.77 217.73 224.11

:::

## Inferencia con la media de la distribuci√≥n posterior

### Pregunta 3

-   Con las distribuciones simuladas de la pregunta anterior, estima la media y la varianza de cada distribuci√≥n. Compara los resultados con los obtenidos en la Pregunta 1.

::: {#respuesta-3 .callout-note}

```{r}
# Estimaci√≥n de la media y varianza para la distribuci√≥n posterior de Clase 1
media_estim_clase_1 <- mean(muestras_clase_1)
varianza_estim_clase_1 <- var(muestras_clase_1)

# Estimaci√≥n de la media y varianza para la distribuci√≥n posterior de Clase 2
media_estim_clase_2 <- mean(muestras_clase_2)
varianza_estim_clase_2 <- var(muestras_clase_2)

# Resultados
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Media_estim = c(media_estim_clase_1, media_estim_clase_2),
  Varianza_estim = c(varianza_estim_clase_1, varianza_estim_clase_2)
)
```

RESPUESTA 

    Clase Media_estim Varianza_estim
1 Clase 1      234.75         78.202
2 Clase 2      222.26         68.673

los resultados son ligeramente distintos. Esto sugiere que las simulaciones est√°n reflejando correctamente la distribuci√≥n posterior. 

:::

## Tama√±o muestral y error est√°ndar de Monte Carlo

### Pregunta 4

-   Calcula el error est√°ndar de Monte Carlo de las medias estimadas por el m√©todo de Monte Carlo [@hoff2009, p. 56], y su intervalo al 95% de confianza (p. 57). Asume que las varianzas verdaderas son desconocidas (i.e., utiliza las varianzas obtenidas por el m√©todo de Monte Carlo). ¬øCu√°l es la amplitud de los intervalos? Comprueba si los valores reales (obtenidos anal√≠ticamente) est√°n comprendidos en los intervalos

::: {#respuesta-4 .callout-note}
```{r}
# Estimaci√≥n de la desviaci√≥n est√°ndar de las muestras
desviacion_clase_1 <- sd(muestras_clase_1)
desviacion_clase_2 <- sd(muestras_clase_2)

# Error est√°ndar de Monte Carlo
emc_clase_1 <- desviacion_clase_1 / sqrt(500)
emc_clase_2 <- desviacion_clase_2 / sqrt(500)

# Valor cr√≠tico t de Student al 95% (usando 499 grados de libertad)
t_95_clase_1 <- qt(0.975, df = 499)
t_95_clase_2 <- qt(0.975, df = 499)

# Intervalos de confianza al 95%
ic_clase_1 <- c(media_estim_clase_1 - t_95_clase_1 * emc_clase_1,
                media_estim_clase_1 + t_95_clase_1 * emc_clase_1)

ic_clase_2 <- c(media_estim_clase_2 - t_95_clase_2 * emc_clase_2,
                media_estim_clase_2 + t_95_clase_2 * emc_clase_2)

# Amplitud de los intervalos
amplitud_clase_1 <- diff(ic_clase_1)
amplitud_clase_2 <- diff(ic_clase_2)

# Comparaci√≥n con los valores reales obtenidos anal√≠ticamente
real_clase_1 <- c(234.81, 71.98) # (Mu_post, Sigma2_post) para clase 1
real_clase_2 <- c(222.34, 66.55) # (Mu_post, Sigma2_post) para clase 2

# Resultados
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Media_estim = c(media_estim_clase_1, media_estim_clase_2),
  Error_estandar_MC = c(emc_clase_1, emc_clase_2),
  Intervalo_inferior = c(ic_clase_1[1], ic_clase_2[1]),
  Intervalo_superior = c(ic_clase_1[2], ic_clase_2[2]),
  Amplitud = c(amplitud_clase_1, amplitud_clase_2),
  Real_Mu_post = c(real_clase_1[1], real_clase_2[1]),
  Dentro_intervalo = c(real_clase_1[1] >= ic_clase_1[1] & real_clase_1[1] <= ic_clase_1[2],
                      real_clase_2[1] >= ic_clase_2[1] & real_clase_2[1] <= ic_clase_2[2])
)
```

RESPUESTA 

-Las medias estimadas por el m√©todo de Monte Carlo son: 
    Clase 1: 234.75
    Clase 2: 222.26 
- Los errores est√°ndar de Monte Carlo de las medias estimadas son: 
    Clase 1: 0.39548
    Clase 2: 0.37060 
- Intervalos al 95% de confianza 
    Clase 1: 233.97 -  235.52 
    Clase 2: 221.53 - 222.99 
- Amplitud de los intervalos 
    Clase 1:  1.5540
    Clase 2:  1.4563
  
  Los valores reales (234.81 y 222.34) est√°n comprendidos dentro de los int√©rvalos. 


:::

### Pregunta 5

-   En base a las varianzas obtenidas por el m√©todo de Monte Carlo, determina el tama√±o muestral de la distribuci√≥n posterior necesario para alcanzar una precisi√≥n de 2 decimales en la estimaci√≥n de la media de las distribuciones posteriores [@hoff2009, p. 56 ---vas a tener que "despejar" el tama√±o de la muestra simulada]. Utiliza el valor mayor de ambas distribuciones para volver a calcular las medias, y comprueba si se alcanza la precisi√≥n esperada.

::: {#respuesta-5 .callout-note}
```{r}
# Suponer que ya se tienen estas desviaciones est√°ndar
desv_est_1 <- sd(muestras_clase_1)
desv_est_2 <- sd(muestras_clase_2)

# Usar el valor m√°s grande de los dos
s_max <- max(desv_est_1, desv_est_2)

# Precisi√≥n deseada
precision_deseada <- 0.005

# Valor t para confianza del 95% (aprox. normal)
t_975 <- 1.96

# Tama√±o muestral necesario
n_necesario <- ceiling((t_975 * s_max / precision_deseada)^2)

n_necesario

# Simula con el tama√±o necesario (por ejemplo, para clase 1)
set.seed(20250419)

n_necesario # ‚Üê deber√≠a mostrarte un n√∫mero tipo 6000‚Äì8000 aprox.

# Nuevas muestras
nuevas_muestras_clase_1 <- rnorm(n_necesario, mean = mu_post_1, sd = sqrt(sigma2_post_1))
nuevas_muestras_clase_2 <- rnorm(n_necesario, mean = mu_post_2, sd = sqrt(sigma2_post_2))

# Estimar medias
media_nueva_1 <- mean(nuevas_muestras_clase_1)
media_nueva_2 <- mean(nuevas_muestras_clase_2)

# Mostrar redondeado a 2 decimales
round(c(media_nueva_1, media_nueva_2), 2)

#VOLVER A SIMULAR CON EL NUEVO TAMA√ëO MUESTRAL 


set.seed(20250318)

# 500 muestras iniciales de cada clase
muestras_clase_1 <- rnorm(500, mean = 234.81, sd = sqrt(71.984))
muestras_clase_2 <- rnorm(500, mean = 222.34, sd = sqrt(66.553))

# Desviaciones est√°ndar estimadas
sd_1 <- sd(muestras_clase_1)
sd_2 <- sd(muestras_clase_2)

# Tomamos la mayor
s_max <- max(sd_1, sd_2)

# Precisi√≥n deseada: ¬±0.005
precision <- 0.005
t_975 <- 1.96  # Valor t para 95% de confianza

# Tama√±o muestral necesario
n_necesario <- ceiling((t_975 * s_max / precision)^2)
n_necesario

set.seed(20250419)

# Simulaci√≥n con tama√±o muestral ajustado
muestras_precisas_clase_1 <- rnorm(n_necesario, mean = 234.81, sd = sqrt(71.984))
muestras_precisas_clase_2 <- rnorm(n_necesario, mean = 222.34, sd = sqrt(66.553))

media_1_precisa <- mean(muestras_precisas_clase_1)
media_2_precisa <- mean(muestras_precisas_clase_2)

# Mostrar redondeadas
round(media_1_precisa, 2)
round(media_2_precisa, 2)

```


RESPUESTAS: 

Tama√±o muestral necesario para alcanzar una precisi√≥n de 2 decimales en la estimaci√≥n de la media de las distribuciones posteriores: 12016790

Media redondeada clase 1: 234.81 
Media redondeada clase 2: 222.34

Se ha alcanzado la precisi√≥n esperada. 

:::

## Inferencia de intervalos y probabilidades

### Pregunta 6

-   Utilizando las distribuciones de alta precisi√≥n obtenidas en la Pregunta 5, calcula:

    -   Los intervalos de credibilidad del 99% de las distribuciones posteriores.

    -   Los cuartiles de las distribuciones posteriores.

    -   La probabilidad de cada clase de tener una media menor a la de la poblaci√≥n.

Obt√©n los resultados anal√≠ticos con las funciones `qnorm()` y `pnorm()`, y compara ambos.

::: {#respuesta-6 .callout-note}
```{r}
# Intervalos de credibilidad del 99% (percentiles 0.5% y 99.5%)
quantile(muestras_precisas_clase_1, probs = c(0.005, 0.995))
quantile(muestras_precisas_clase_2, probs = c(0.005, 0.995))

# Par√°metros anal√≠ticos usando qnorm
mu_post_1 <- 234.81
mu_post_2 <- 222.34
sigma_post_1 <- sqrt(71.984)
sigma_post_2 <- sqrt(66.553)

# Intervalos del 99%
qnorm(c(0.005, 0.995), mean = mu_post_1, sd = sigma_post_1)
qnorm(c(0.005, 0.995), mean = mu_post_2, sd = sigma_post_2)

# Monte Carlo
quantile(muestras_precisas_clase_1, probs = c(0.25, 0.5, 0.75))
quantile(muestras_precisas_clase_2, probs = c(0.25, 0.5, 0.75))

# Anal√≠tico
qnorm(c(0.25, 0.5, 0.75), mean = mu_post_1, sd = sigma_post_1)
qnorm(c(0.25, 0.5, 0.75), mean = mu_post_2, sd = sigma_post_2)

#Probabilidad de que la media sea menor que la media de la poblaci√≥n 

#MONTECARLO 

mean(muestras_precisas_clase_1 < 247)
mean(muestras_precisas_clase_2 < 247)

#ANAL√çTICO

pnorm(247, mean = mu_post_1, sd = sigma_post_1)
pnorm(247, mean = mu_post_2, sd = sigma_post_2)

```


RESPUESTA 

1. INTERVALOS DE CREDIBILIDAD DEL 99% (MONTE CARLO Y ANAL√çTICO)

CLASE 1: 212.98 - 256.66
CLASE 2: 201.35 - 243.37 

2. PAR√ÅMETROS ANAL√çTICOS USANDO qnorm (): 

CLASE 1: 212.96 - 256.66
CLASE 2: 201.33 - 243.35

3. CUARTILES DE LAS DISTRIBUCIONES POSTERIORES 

 MONTECARLO: 
 
  CLASE 1: 
    25%: 229.09 
    50%: 234.81 
    75%: 240.53 
    
  CLASE 2: 
    25%: 216.84
    50%: 222.34 
    75%: 227.84 
    
 ANAL√çTICO: 
 
 CLASE 1: 
    0.25: 229.09
    0.5: 234.81
    0.75: 240.53
    
  CLASE 2: 
    0.25: 216.84
    0.5: 222.34
    0.75: 227.84
 
3. PROBABILIDAD DE QUE LA MEDIA SEA MENOR QUE LA MEDIA DE LA POBLACI√ìN 

MONTECARLO:

  clase 1: 0.92472
  clase 2: 0.99874
  
ANAL√çTICO: 

  clase 1: 0.92461
  clase 2: 0.99875

:::

## Reflexi√≥n sobre el m√©todo de Monte Carlo

### Pregunta 7p

-   ¬øQu√© opinas del m√©todo de Monte Carlo? ¬øTe resulta f√°cil o dif√≠cil de aplicar? ¬øQu√© consideras que aporta respecto de obtener los par√°metros de los modelos aplicando las f√≥rmulas anal√≠ticas?

::: {#respuesta-7 .callout-note}

Me ha parecido una herramienta adicional muy √∫til. Aunque al principio parece complicado y no se comprende del todo su necesidad frente al modelo anal√≠tico, una vez se realiza en R seg√∫n los pasos que indica el ejercicio, he visto que es intuitivo y f√°cil de usar. Adem√°s, los resultados mediante este m√©todo fueron muy cercanos al m√©todo anal√≠tico. Considero que este modelo aporta m√°s realismo, es decir, es muy util para situaciones que son mas reales y complicadas.El plus que le veo es que puedes calcular probabilidades, intervalos de confianza y cuartiles. 

:::

## Inferencia con funciones derivadas

### Pregunta 8

-   Calcula la probabilidad de que la media de la segunda clase sea superior a la media de la primera clase usando el m√©todo de Monte Carlo. ¬øC√≥mo lo har√≠as usando la f√≥rmula anal√≠tica? ¬øEs m√°s f√°cil o m√°s dif√≠cil?

::: {#respuesta-8 .callout-note}

C√ÅLCULO 

```{r}
# Probabilidad de que la media de la clase 2 sea mayor que la de la clase 1 M√âTODO MONTECARLO

prob_mc <- mean(muestras_precisas_clase_2 > muestras_precisas_clase_1)
prob_mc
```

RESPUESTA: PROBABILIDAD DE QUE LA MEDIA DE LA CLASE 2 SEA MAYOR QUE LA DE LA CLASE 1
0.1446

```{r}
#Probabilidad de que la media de la clase 2 sea mayor que la de la clase 1 M√âTODO ANAL√çTICO

# Diferencia de medias
mu_diff <- mu_post_2 - mu_post_1

# Desviaci√≥n t√≠pica de la diferencia
sigma_diff <- sqrt(sigma_post_1^2 + sigma_post_2^2)

# Probabilidad de que la media de clase 2 sea mayor que la de clase 1
prob_analitica <- 1 - pnorm(0, mean = mu_diff, sd = sigma_diff)
prob_analitica
```

RESPUESTA: PROBABILIDAD DE QUE LA MEDIA DE LA CLASE 2 SEA MAYOR QUE LA DE LA CLASE 1
0.1447
 
Es m√°s f√°cil e intuitivo el c√°lculo de Monte Carlo porque solo hay que comparar cada valor de la media simulada de la clase 2 con cada valor de la media simulada de la clase 1. Mientras que es m√°s complicado el anal√≠tico porque hay que calcular varianzas y medias.
 
:::

### Pregunta 9

-   Las muestras obtenidas para distribuci√≥n posterior de la media de cada una de las dos clases son independientes. Por lo tanto, deber√≠a dar igual en qu√© orden se hayan muestreado. Utilizando `sample(_vector_)` podemos obtener los valores aleatorizado del vector en un objeto `_vector_`. Comprueba si se cumple que podemos aleatorizar las muestras de una (o ambas) distribuciones posteriores, y que la probabilidad de que las dos clases sean diferentes a√∫n as√≠ no cambie.

::: {#respuesta-9 .callout-note}

```{r}
# Obtener las muestras de las distribuciones posteriores
set.seed(20250318)  

#Probabilidad original de que la media de clase 2 sea mayor que la de clase 1
prob_original <- mean(muestras_precisas_clase_2 > muestras_precisas_clase_1)

# Aleatorizar las muestras (muestra las distribuciones posterior de manera aleatoria)
muestras_precisas_clase_1_aleatorizada <- sample(muestras_precisas_clase_1)
muestras_precisas_clase_2_aleatorizada <- sample(muestras_precisas_clase_2)

# Paso 4: Calcular la probabilidad despu√©s de aleatorizar
prob_aleatorizada <- mean(muestras_precisas_clase_2_aleatorizada > muestras_precisas_clase_1_aleatorizada)

# Paso 5: Comparar las probabilidades
prob_original
prob_aleatorizada
```

RESPUESTAS 

Probabilidad original: 0.1446
Probabilidad aleatorizada: 0.14463

Se comprueba que aunque se aleatorice la muestra de las distribuciones posteriores, la probabilidad de que las clases sean diferentes no cambia. 

:::

## Estimador m√°ximo posterior

El estimador m√°ximo posterior (MAP) de la media es, simplemente, la moda de la distribuci√≥n posterior.
Es decir, el valor de la media para el que la densidad de la distribuci√≥n posterior es m√°xima.

Con la expresi√≥n cerrada de la distribuci√≥n posterior normal, sabemos que la moda coincide con el valor central o media.

Con cualquier otra expresi√≥n cerrada, podemos utilizar un algoritmo de optimizaci√≥n para encontrar ese m√°ximo.

Cuando no conocemos la expresi√≥n cerrada, sin embargo, necesitaremos utilizar el m√©todo de Monte Carlo (veremos c√≥mo en un tema posterior).
No obstante, obtener la moda a partir de una muestra es algo m√°s complicado que simplemente "resumir" las muestras de la distribuci√≥n posterior.

Una forma de hacerlo es utilizando un histograma.
Sin embargo, esto es "rudimentario", y no est√° claro qu√© ancho deben tener las bandas.

La forma id√≥nea es obteniendo la densidad mediante un "suavizado", algoritmo llamado "kernel density estimation".

Vamos a ver un ejemplo con una distribuci√≥n normal est√°ndar.
Sabemos que el algoritmo deber√≠a devolver el valor "0", que se corresponde con el m√°ximo de esta distribuci√≥n.

```{r map-mc-normal-estandar}
N_MC <- 50000L # Tama√±o muestral para la simulaci√≥n de la distribui√≥n.

muestras_norm <- rnorm(N_MC) # Simulamos las muestras de la distribuci√≥n

densidad_norm <- density(muestras_norm) # `density()` aplica el "suavizado"

# Convertimos la densidad en un "tibble" para manejarla m√°s f√°cilmente 
densidad_normal <- tibble(
  x        = densidad_norm$x, # `x` == variable aleatoria
  densidad = densidad_norm$y
)

# Podemos representar la densidad gr√°ficamente, junto con la curva normal:
densidad_normal |>
  mutate(dens_analitica = dnorm(x)) |>
  ggplot(aes(x, densidad)) +
  geom_line(color = color_defecto) +
  geom_line(aes(y = dens_analitica), color = PALETA[2])

# Obtenemos el valor de la moda:
estimador_map <- densidad_normal |> slice(which.max(densidad))
densidad_max  <- estimador_map |> pull(densidad)
moda          <- estimador_map |> pull(x)
```

El estimador MAP es `{r} moda`, siendo su densidad `{r} densidad_max`.

### Pregunta 10

-   Utilizando las muestras posteriores obtenidas en la pregunta 5, calcula los estimadores MAP para las dos clases, y comp√°ralos con los que obtendr√≠as con las f√≥mulas anal√≠ticas.

::: {#respuesta-10 .callout-note}

```{r}
# Estimador MAP utilizando las muestras posteriores
map_clase_1 <- mean(muestras_precisas_clase_1)
map_clase_2 <- mean(muestras_precisas_clase_2)

# Estimador MAP anal√≠tico (media posterior) 
mu_post_1_analitico <- 234.81  # Seg√∫n lo obtenido en la pregunta 5
mu_post_2_analitico <- 222.34  # Seg√∫n lo obtenido en la pregunta 5

# Comparar los estimadores MAP con los valores anal√≠ticos
map_clase_1
map_clase_2
mu_post_1_analitico
mu_post_2_analitico

```


RESPUESTA 

ESTIMADORES MAP 
  Clase 1: 234.81
  Clase 2: 222.34
  
MU POST ANAL√çTICO 
  Clase 1: 234.81
  Clase 2: 222.34
  
los resultados obtenidos son iguales en ambos casos. 

:::

# Ejercicio 2: Distribuciones Gamma

## Diferencia entre distribuciones

En el texto de @hoff2009 se utiliza una distribuci√≥n Gamma en un ejemplo comparando las tasas de fertilidad de mujeres de 40 a√±os con y sin t√≠tulo universitario, obtenido de la Encuesta Social General de los EEUU durante los a√±os 1990 [puedes consultar los detalles en el cap√≠tulo 3 de @hoff2009].
Las distribuciones posteriores de la tasa de fertilidad de cada grupo son (p. .53):

$$
p(\theta_{sin} | y) = gamma(\theta_{sin}, 219, 112)
$$

$$
p(\theta_{con} | y) = gamma(\theta_{con}, 68, 45)
$$

La distribuci√≥n Gamma est√° implementada en R mediante la familia de funciones `*gamma()`: `rgamma()`, `dgamma()`, `pgamma()`, y `qgamma()`.

### Pregunta 11

-   Utilizando un eje horizontal con precisi√≥n de .002, representa las dos distribuciones. Determina los l√≠mites del eje horizontal seg√∫n tu propio criterio. Sin ver la forma de la funci√≥n de densidad, ¬øpodr√≠as deducir cu√°l habr√≠a de ser alguno de los dos l√≠mites del intervalo?

::: {#respuesta-11 .callout-note}
```{r}

# Par√°metros de las distribuciones Gamma
shape_sin <- 219
scale_sin <- 112
shape_con <- 68
scale_con <- 45

# Determinar los l√≠mites del eje horizontal
x_min <- 0  # No tiene sentido valores negativos para estas distribuciones
x_max <- max(qgamma(0.999, shape_sin, scale_sin), qgamma(0.999, shape_con, scale_con))

# Generar un vector de valores para el eje horizontal con precisi√≥n de 0.002
x_vals <- seq(x_min, x_max, by = 0.002)

# Calcular las funciones de densidad para las distribuciones Gamma
y_sin <- dgamma(x_vals, shape_sin, scale_sin)
y_con <- dgamma(x_vals, shape_con, scale_con)

# Graficar las distribuciones Gamma
plot(x_vals, y_sin, type = "l", col = "blue", lwd = 2, 
     xlab = "Tasa de fertilidad", ylab = "Densidad", 
     main = "Distribuciones Gamma de tasa de fertilidad")
lines(x_vals, y_con, col = "red", lwd = 2)
legend("topright", legend = c("Sin t√≠tulo universitario", "Con t√≠tulo universitario"), 
       col = c("blue", "red"), lwd = 2)

```


RESPUESTA 

Alguno de los dos l√≠mites del intervalo debe ser en referencia a la media. El valor de la media debe encontrarse dentro de los l√≠mites y al saber que se sesga a la derecha hay que tomar en cuenta los valores del extremo superior. As√≠ tomando en cuenta esto, los valores que deben estar son algun valor menor a 3060 (media de theta con) y alg√∫n valor superior a 24528 (media de theta sin). As√≠ el l√≠mite superior podr√≠as ser 25000.

:::

### Pregunta 12

-   Determina la probabilidad de que las mujeres de 40 a√±os sin t√≠tulo universitario en los 90 en EEUU tuvieran una tasa de fertilidad superior a la de las mujeres con t√≠tulo universitario. Utiliza el m√©todo de Monte Carlo con 3 decimales de precisi√≥n al 99% de confianza, justificando el tama√±o muestral elegido para aproximar las distribuciones posteriores (usa la media para justificar esta precisi√≥n). Si lo necesitas, revisa el material complementario del Tema 3 para determinar la varianza de la distribuci√≥n Gamma.

::: {#respuesta-12 .callout-note}

```{r}
# Definir par√°metros
n_muestras <- 18284  # Tama√±o de la muestra

# Generar muestras para las dos distribuciones Gamma
muestras_sin_titulo <- rgamma(n_muestras, shape = 219, scale = 112)
muestras_con_titulo <- rgamma(n_muestras, shape = 68, scale = 45)

# Calcular la probabilidad de que las mujeres sin t√≠tulo tengan tasa de fertilidad superior
probabilidad_mc <- mean(muestras_sin_titulo > muestras_con_titulo)
probabilidad_mc
```

RESPUESTA 

probabilidad calculada: 1

Justificaci√≥n tama√±o muestral:

He elegido un tama√±o muestral de 18,284 simulaciones. Este n√∫mero sale al aplicar la f√≥rmula del error est√°ndar de Monte Carlo, usando la media aproximada de la distribuci√≥n (ùúá= 24.528 y su varianza (ùúé2=1657.75).
Como el objetivo es tener una precisi√≥n de tres decimales, hay que asegurar que el error de la media simulada no supere 0.0005 veces la media. Al sustituir todo en la f√≥rmula, da como resultado ese tama√±o muestral. As√≠ me aseguro de que la estimaci√≥n de la media es lo bastante precisa para lo que pide el ejercicio.
:::

# Referencias
