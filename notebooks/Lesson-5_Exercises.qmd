---
title: "Tema 5: Ejercicio"
format:
  html:
    code-copy:       true
    code-tools:      true
    df-print:        paged
    embed-resources: true
    theme:           ../www/extra-styles.scss
    toc:             true
    toc-location:    left
bibliography:        ../www/abd.bib
csl:                 ../www/apa-old-doi-prefix.csl
callout-appearance: minimal
---

# Introducción

En este tema hemos estudiado el método de Monte Carlo.
Ahora vamos a ponerlo en práctica, comparando sus resultados con lo que ya conocemos de temas anteriores.
En esta ocasión, la entrega consiste en un ejercicio sobre el modelo normal-normal, y otro sobre el modelo Poisson-Gamma.

Al igual que en el Tema 3, configuramos primero el entorno.

```{r setup}
#| message: false

# Paquetes:
library(tidyverse)
library(RColorBrewer)


# Configuración de la salida gráfica:

PALETA <- brewer.pal(8, "Set2") # Colores por defecto
color_defecto  <- PALETA[1]
options(ggplot2.discrete.colour = PALETA)

theme_set(theme_bw()) # Tema "neutro" para la representación gráfica

# Redondea los números reales "inline":
options(digits = 3L)                
options(knitr.digits.signif = FALSE)
```

# Ejercicio 1: Modelo normal-normal

## Ajuste de modelos

En este ejercicio vamos a utilizar nuevamente el modelo normal-normal del [Ejercicio 4 del Tema 3](https://github.com/DV-Morillo/Ejercicios-ABD/blob/main/notebooks/Lesson-3_Exercises.qmd#L382).

Aquí tienes nuevamente los datos:

```{r normal-normal-muestras}
# Tiempo en s para leer un texto estándar en una prueba de lectura de las 2
#   clases de 1º de ESO en un colegio:
clase_1 <- tibble(
  id     = 1:27,
  tiempo = c(
    242, 249, 278, 273, 227, 257, 276, 236, 214, 141, 200, 201, 
    228, 271, 160, 275, 156, 246, 293, 306, 263, 247, 224, 160, 277, 
    168, 250
  )
)

clase_2 <- tibble(
  id     = 1:24,
  tiempo = c(
    195, 176, 237, 258, 226, 254, 292, 212, 215, 298, 235, 244, 
    144, 227, 166, 194, 261, 187, 224, 233, 180, 167, 193, 282
  )
)
```

Los datos de la distribución previa eran los datos de la población.
Recuerda:

```{r normal-normal-previa-params}
MU_PREVIA     <- 247
SIGMA2_PREVIA <-  34^2
```

Aplicando la propiedad de conjugación, recuerda que podemos obtener la expresión analítica de la distribución posterior de la media:

$p(\mu | y) = N(\mu_{post}, \sigma^2_{post})$,

siendo

$$
\mu\_{post} = \frac{\sigma^2_y \mu_{pre} + n \sigma^2_{pre} \bar{y}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

y

$$
\sigma^2\_{post} = \frac{\sigma^2_y \sigma^2_{pre}}
                   {\sigma^2_y + n \sigma^2_{pre}}
$$

### Pregunta 1

-   Utilizando la expresión analítica del modelo, obtén la expresión analítica de la distribución posterior de la media para cada una de las dos clases, con 2 decimales.

::: {#respuesta-1 .callout-note}

#Estadísticos muestrales de cada clase 
```{r}
resumen <- bind_rows(
  clase_1 %>% summarise(
    clase = "clase_1",
    n = n(),
    media = mean(tiempo),
    varianza = var(tiempo)
  ),
  clase_2 %>% summarise(
    clase = "clase_2",
    n = n(),
    media = mean(tiempo),
    varianza = var(tiempo)
  )
)

resumen
```


RESPUESTA 

clase       n media varianza
  <chr>   <int> <dbl>    <dbl>
1 clase_1    27  234     2073.
2 clase_2    24  221.    1695.

#Parámetros de la distribución posterior

# Parámetros de la distribución previa

```{r}
MU_PREVIA     <- 247
SIGMA2_PREVIA <- 34^2
```

# Distribución posterior para Clase 1
```{r}
mu_post_1     <- (resumen$varianza[1] * MU_PREVIA + resumen$n[1] * SIGMA2_PREVIA * resumen$media[1]) /
                 (resumen$varianza[1] + resumen$n[1] * SIGMA2_PREVIA)

sigma2_post_1 <- (resumen$varianza[1] * SIGMA2_PREVIA) /
                 (resumen$varianza[1] + resumen$n[1] * SIGMA2_PREVIA)
```


# Distribución posterior para Clase 2
```{r}
mu_post_2     <- (resumen$varianza[2] * MU_PREVIA + resumen$n[2] * SIGMA2_PREVIA * resumen$media[2]) /
                 (resumen$varianza[2] + resumen$n[2] * SIGMA2_PREVIA)

sigma2_post_2 <- (resumen$varianza[2] * SIGMA2_PREVIA) /
                 (resumen$varianza[2] + resumen$n[2] * SIGMA2_PREVIA)

```

# Resultados
```{r}
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Mu_post = c(mu_post_1, mu_post_2),
  Sigma2_post = c(sigma2_post_1, sigma2_post_2)
)
```


RESPUESTA 

Clase Mu_post Sigma2_post
1 Clase 1  234.81      71.984
2 Clase 2  222.34      66.553

:::

## Simulación de Monte Carlo

Para cada familia de distribuciones de probabilidad existe la función `r*()` en R que permite simular valores de esa distribución.
Por ejemplo, en el caso de la normal, `rnorm(10, mean = 1, sd = 0)` extrae 10 muestras "independientes e igualmente distribuidas" de una distribución normal estándar.

### Pregunta 2

-   Para cada una de las dos clases, extrae 500 muestras de la distribución posterior.

*(Recomendación: Inicializa la "semilla aleatoria" para evitar tener valores diferentes en cada ejecución)*

```{r inicializa-semilla}
set.seed(20250318)
```

::: {#respuesta-2 .callout-note}

```{r}
# Inicialización de la semilla para asegurar la reproducibilidad
set.seed(20250318)

# Extraer 500 muestras para cada clase de su distribución posterior
muestras_clase_1 <- rnorm(500, mean = mu_post_1, sd = sqrt(sigma2_post_1))
muestras_clase_2 <- rnorm(500, mean = mu_post_2, sd = sqrt(sigma2_post_2))

# Ver los primeros resultados de las muestras generadas
head(muestras_clase_1)
head(muestras_clase_2)
```


RESPUESTA PRIMEROS RESULTADOS GENERADOS 

CLASE 1: 
214.51 240.04 240.37 230.34 230.39 227.97

ClASE 2:
224.03 222.57 227.19 230.77 217.73 224.11

:::

## Inferencia con la media de la distribución posterior

### Pregunta 3

-   Con las distribuciones simuladas de la pregunta anterior, estima la media y la varianza de cada distribución. Compara los resultados con los obtenidos en la Pregunta 1.

::: {#respuesta-3 .callout-note}

```{r}
# Estimación de la media y varianza para la distribución posterior de Clase 1
media_estim_clase_1 <- mean(muestras_clase_1)
varianza_estim_clase_1 <- var(muestras_clase_1)

# Estimación de la media y varianza para la distribución posterior de Clase 2
media_estim_clase_2 <- mean(muestras_clase_2)
varianza_estim_clase_2 <- var(muestras_clase_2)

# Resultados
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Media_estim = c(media_estim_clase_1, media_estim_clase_2),
  Varianza_estim = c(varianza_estim_clase_1, varianza_estim_clase_2)
)
```

RESPUESTA 

    Clase Media_estim Varianza_estim
1 Clase 1      234.75         78.202
2 Clase 2      222.26         68.673

los resultados son ligeramente distintos. Esto sugiere que las simulaciones están reflejando correctamente la distribución posterior. 

:::

## Tamaño muestral y error estándar de Monte Carlo

### Pregunta 4

-   Calcula el error estándar de Monte Carlo de las medias estimadas por el método de Monte Carlo [@hoff2009, p. 56], y su intervalo al 95% de confianza (p. 57). Asume que las varianzas verdaderas son desconocidas (i.e., utiliza las varianzas obtenidas por el método de Monte Carlo). ¿Cuál es la amplitud de los intervalos? Comprueba si los valores reales (obtenidos analíticamente) están comprendidos en los intervalos

::: {#respuesta-4 .callout-note}
```{r}
# Estimación de la desviación estándar de las muestras
desviacion_clase_1 <- sd(muestras_clase_1)
desviacion_clase_2 <- sd(muestras_clase_2)

# Error estándar de Monte Carlo
emc_clase_1 <- desviacion_clase_1 / sqrt(500)
emc_clase_2 <- desviacion_clase_2 / sqrt(500)

# Valor crítico t de Student al 95% (usando 499 grados de libertad)
t_95_clase_1 <- qt(0.975, df = 499)
t_95_clase_2 <- qt(0.975, df = 499)

# Intervalos de confianza al 95%
ic_clase_1 <- c(media_estim_clase_1 - t_95_clase_1 * emc_clase_1,
                media_estim_clase_1 + t_95_clase_1 * emc_clase_1)

ic_clase_2 <- c(media_estim_clase_2 - t_95_clase_2 * emc_clase_2,
                media_estim_clase_2 + t_95_clase_2 * emc_clase_2)

# Amplitud de los intervalos
amplitud_clase_1 <- diff(ic_clase_1)
amplitud_clase_2 <- diff(ic_clase_2)

# Comparación con los valores reales obtenidos analíticamente
real_clase_1 <- c(234.81, 71.98) # (Mu_post, Sigma2_post) para clase 1
real_clase_2 <- c(222.34, 66.55) # (Mu_post, Sigma2_post) para clase 2

# Resultados
data.frame(
  Clase = c("Clase 1", "Clase 2"),
  Media_estim = c(media_estim_clase_1, media_estim_clase_2),
  Error_estandar_MC = c(emc_clase_1, emc_clase_2),
  Intervalo_inferior = c(ic_clase_1[1], ic_clase_2[1]),
  Intervalo_superior = c(ic_clase_1[2], ic_clase_2[2]),
  Amplitud = c(amplitud_clase_1, amplitud_clase_2),
  Real_Mu_post = c(real_clase_1[1], real_clase_2[1]),
  Dentro_intervalo = c(real_clase_1[1] >= ic_clase_1[1] & real_clase_1[1] <= ic_clase_1[2],
                      real_clase_2[1] >= ic_clase_2[1] & real_clase_2[1] <= ic_clase_2[2])
)
```

RESPUESTA 

-Las medias estimadas por el método de Monte Carlo son: 
    Clase 1: 234.75
    Clase 2: 222.26 
- Los errores estándar de Monte Carlo de las medias estimadas son: 
    Clase 1: 0.39548
    Clase 2: 0.37060 
- Intervalos al 95% de confianza 
    Clase 1: 233.97 -  235.52 
    Clase 2: 221.53 - 222.99 
- Amplitud de los intervalos 
    Clase 1:  1.5540
    Clase 2:  1.4563
  
  Los valores reales (234.81 y 222.34) están comprendidos dentro de los intérvalos. 


:::

### Pregunta 5

-   En base a las varianzas obtenidas por el método de Monte Carlo, determina el tamaño muestral de la distribución posterior necesario para alcanzar una precisión de 2 decimales en la estimación de la media de las distribuciones posteriores [@hoff2009, p. 56 ---vas a tener que "despejar" el tamaño de la muestra simulada]. Utiliza el valor mayor de ambas distribuciones para volver a calcular las medias, y comprueba si se alcanza la precisión esperada.

::: {#respuesta-5 .callout-note}
```{r}
# Suponer que ya se tienen estas desviaciones estándar
desv_est_1 <- sd(muestras_clase_1)
desv_est_2 <- sd(muestras_clase_2)

# Usar el valor más grande de los dos
s_max <- max(desv_est_1, desv_est_2)

# Precisión deseada
precision_deseada <- 0.005

# Valor t para confianza del 95% (aprox. normal)
t_975 <- 1.96

# Tamaño muestral necesario
n_necesario <- ceiling((t_975 * s_max / precision_deseada)^2)

n_necesario

# Simula con el tamaño necesario (por ejemplo, para clase 1)
set.seed(20250419)

n_necesario # ← debería mostrarte un número tipo 6000–8000 aprox.

# Nuevas muestras
nuevas_muestras_clase_1 <- rnorm(n_necesario, mean = mu_post_1, sd = sqrt(sigma2_post_1))
nuevas_muestras_clase_2 <- rnorm(n_necesario, mean = mu_post_2, sd = sqrt(sigma2_post_2))

# Estimar medias
media_nueva_1 <- mean(nuevas_muestras_clase_1)
media_nueva_2 <- mean(nuevas_muestras_clase_2)

# Mostrar redondeado a 2 decimales
round(c(media_nueva_1, media_nueva_2), 2)

#VOLVER A SIMULAR CON EL NUEVO TAMAÑO MUESTRAL 


set.seed(20250318)

# 500 muestras iniciales de cada clase
muestras_clase_1 <- rnorm(500, mean = 234.81, sd = sqrt(71.984))
muestras_clase_2 <- rnorm(500, mean = 222.34, sd = sqrt(66.553))

# Desviaciones estándar estimadas
sd_1 <- sd(muestras_clase_1)
sd_2 <- sd(muestras_clase_2)

# Tomamos la mayor
s_max <- max(sd_1, sd_2)

# Precisión deseada: ±0.005
precision <- 0.005
t_975 <- 1.96  # Valor t para 95% de confianza

# Tamaño muestral necesario
n_necesario <- ceiling((t_975 * s_max / precision)^2)
n_necesario

set.seed(20250419)

# Simulación con tamaño muestral ajustado
muestras_precisas_clase_1 <- rnorm(n_necesario, mean = 234.81, sd = sqrt(71.984))
muestras_precisas_clase_2 <- rnorm(n_necesario, mean = 222.34, sd = sqrt(66.553))

media_1_precisa <- mean(muestras_precisas_clase_1)
media_2_precisa <- mean(muestras_precisas_clase_2)

# Mostrar redondeadas
round(media_1_precisa, 2)
round(media_2_precisa, 2)

```


RESPUESTAS: 

Tamaño muestral necesario para alcanzar una precisión de 2 decimales en la estimación de la media de las distribuciones posteriores: 12016790

Media redondeada clase 1: 234.81 
Media redondeada clase 2: 222.34

Se ha alcanzado la precisión esperada. 

:::

## Inferencia de intervalos y probabilidades

### Pregunta 6

-   Utilizando las distribuciones de alta precisión obtenidas en la Pregunta 5, calcula:

    -   Los intervalos de credibilidad del 99% de las distribuciones posteriores.

    -   Los cuartiles de las distribuciones posteriores.

    -   La probabilidad de cada clase de tener una media menor a la de la población.

Obtén los resultados analíticos con las funciones `qnorm()` y `pnorm()`, y compara ambos.

::: {#respuesta-6 .callout-note}
```{r}
# Intervalos de credibilidad del 99% (percentiles 0.5% y 99.5%)
quantile(muestras_precisas_clase_1, probs = c(0.005, 0.995))
quantile(muestras_precisas_clase_2, probs = c(0.005, 0.995))

# Parámetros analíticos usando qnorm
mu_post_1 <- 234.81
mu_post_2 <- 222.34
sigma_post_1 <- sqrt(71.984)
sigma_post_2 <- sqrt(66.553)

# Intervalos del 99%
qnorm(c(0.005, 0.995), mean = mu_post_1, sd = sigma_post_1)
qnorm(c(0.005, 0.995), mean = mu_post_2, sd = sigma_post_2)

# Monte Carlo
quantile(muestras_precisas_clase_1, probs = c(0.25, 0.5, 0.75))
quantile(muestras_precisas_clase_2, probs = c(0.25, 0.5, 0.75))

# Analítico
qnorm(c(0.25, 0.5, 0.75), mean = mu_post_1, sd = sigma_post_1)
qnorm(c(0.25, 0.5, 0.75), mean = mu_post_2, sd = sigma_post_2)

#Probabilidad de que la media sea menor que la media de la población 

#MONTECARLO 

mean(muestras_precisas_clase_1 < 247)
mean(muestras_precisas_clase_2 < 247)

#ANALÍTICO

pnorm(247, mean = mu_post_1, sd = sigma_post_1)
pnorm(247, mean = mu_post_2, sd = sigma_post_2)

```


RESPUESTA 

1. INTERVALOS DE CREDIBILIDAD DEL 99% (MONTE CARLO Y ANALÍTICO)

CLASE 1: 212.98 - 256.66
CLASE 2: 201.35 - 243.37 

2. PARÁMETROS ANALÍTICOS USANDO qnorm (): 

CLASE 1: 212.96 - 256.66
CLASE 2: 201.33 - 243.35

3. CUARTILES DE LAS DISTRIBUCIONES POSTERIORES 

 MONTECARLO: 
 
  CLASE 1: 
    25%: 229.09 
    50%: 234.81 
    75%: 240.53 
    
  CLASE 2: 
    25%: 216.84
    50%: 222.34 
    75%: 227.84 
    
 ANALÍTICO: 
 
 CLASE 1: 
    0.25: 229.09
    0.5: 234.81
    0.75: 240.53
    
  CLASE 2: 
    0.25: 216.84
    0.5: 222.34
    0.75: 227.84
 
3. PROBABILIDAD DE QUE LA MEDIA SEA MENOR QUE LA MEDIA DE LA POBLACIÓN 

MONTECARLO:

  clase 1: 0.92472
  clase 2: 0.99874
  
ANALÍTICO: 

  clase 1: 0.92461
  clase 2: 0.99875

:::

## Reflexión sobre el método de Monte Carlo

### Pregunta 7p

-   ¿Qué opinas del método de Monte Carlo? ¿Te resulta fácil o difícil de aplicar? ¿Qué consideras que aporta respecto de obtener los parámetros de los modelos aplicando las fórmulas analíticas?

::: {#respuesta-7 .callout-note}

Me ha parecido una herramienta adicional muy útil. Aunque al principio parece complicado y no se comprende del todo su necesidad frente al modelo analítico, una vez se realiza en R según los pasos que indica el ejercicio, he visto que es intuitivo y fácil de usar. Además, los resultados mediante este método fueron muy cercanos al método analítico. Considero que este modelo aporta más realismo, es decir, es muy util para situaciones que son mas reales y complicadas.El plus que le veo es que puedes calcular probabilidades, intervalos de confianza y cuartiles. 

:::

## Inferencia con funciones derivadas

### Pregunta 8

-   Calcula la probabilidad de que la media de la segunda clase sea superior a la media de la primera clase usando el método de Monte Carlo. ¿Cómo lo harías usando la fórmula analítica? ¿Es más fácil o más difícil?

::: {#respuesta-8 .callout-note}

CÁLCULO 

```{r}
# Probabilidad de que la media de la clase 2 sea mayor que la de la clase 1 MÉTODO MONTECARLO

prob_mc <- mean(muestras_precisas_clase_2 > muestras_precisas_clase_1)
prob_mc
```

RESPUESTA: PROBABILIDAD DE QUE LA MEDIA DE LA CLASE 2 SEA MAYOR QUE LA DE LA CLASE 1
0.1446

```{r}
#Probabilidad de que la media de la clase 2 sea mayor que la de la clase 1 MÉTODO ANALÍTICO

# Diferencia de medias
mu_diff <- mu_post_2 - mu_post_1

# Desviación típica de la diferencia
sigma_diff <- sqrt(sigma_post_1^2 + sigma_post_2^2)

# Probabilidad de que la media de clase 2 sea mayor que la de clase 1
prob_analitica <- 1 - pnorm(0, mean = mu_diff, sd = sigma_diff)
prob_analitica
```

RESPUESTA: PROBABILIDAD DE QUE LA MEDIA DE LA CLASE 2 SEA MAYOR QUE LA DE LA CLASE 1
0.1447
 
Es más fácil e intuitivo el cálculo de Monte Carlo porque solo hay que comparar cada valor de la media simulada de la clase 2 con cada valor de la media simulada de la clase 1. Mientras que es más complicado el analítico porque hay que calcular varianzas y medias.
 
:::

### Pregunta 9

-   Las muestras obtenidas para distribución posterior de la media de cada una de las dos clases son independientes. Por lo tanto, debería dar igual en qué orden se hayan muestreado. Utilizando `sample(_vector_)` podemos obtener los valores aleatorizado del vector en un objeto `_vector_`. Comprueba si se cumple que podemos aleatorizar las muestras de una (o ambas) distribuciones posteriores, y que la probabilidad de que las dos clases sean diferentes aún así no cambie.

::: {#respuesta-9 .callout-note}

```{r}
# Obtener las muestras de las distribuciones posteriores
set.seed(20250318)  

#Probabilidad original de que la media de clase 2 sea mayor que la de clase 1
prob_original <- mean(muestras_precisas_clase_2 > muestras_precisas_clase_1)

# Aleatorizar las muestras (muestra las distribuciones posterior de manera aleatoria)
muestras_precisas_clase_1_aleatorizada <- sample(muestras_precisas_clase_1)
muestras_precisas_clase_2_aleatorizada <- sample(muestras_precisas_clase_2)

# Paso 4: Calcular la probabilidad después de aleatorizar
prob_aleatorizada <- mean(muestras_precisas_clase_2_aleatorizada > muestras_precisas_clase_1_aleatorizada)

# Paso 5: Comparar las probabilidades
prob_original
prob_aleatorizada
```

RESPUESTAS 

Probabilidad original: 0.1446
Probabilidad aleatorizada: 0.14463

Se comprueba que aunque se aleatorice la muestra de las distribuciones posteriores, la probabilidad de que las clases sean diferentes no cambia. 

:::

## Estimador máximo posterior

El estimador máximo posterior (MAP) de la media es, simplemente, la moda de la distribución posterior.
Es decir, el valor de la media para el que la densidad de la distribución posterior es máxima.

Con la expresión cerrada de la distribución posterior normal, sabemos que la moda coincide con el valor central o media.

Con cualquier otra expresión cerrada, podemos utilizar un algoritmo de optimización para encontrar ese máximo.

Cuando no conocemos la expresión cerrada, sin embargo, necesitaremos utilizar el método de Monte Carlo (veremos cómo en un tema posterior).
No obstante, obtener la moda a partir de una muestra es algo más complicado que simplemente "resumir" las muestras de la distribución posterior.

Una forma de hacerlo es utilizando un histograma.
Sin embargo, esto es "rudimentario", y no está claro qué ancho deben tener las bandas.

La forma idónea es obteniendo la densidad mediante un "suavizado", algoritmo llamado "kernel density estimation".

Vamos a ver un ejemplo con una distribución normal estándar.
Sabemos que el algoritmo debería devolver el valor "0", que se corresponde con el máximo de esta distribución.

```{r map-mc-normal-estandar}
N_MC <- 50000L # Tamaño muestral para la simulación de la distribuión.

muestras_norm <- rnorm(N_MC) # Simulamos las muestras de la distribución

densidad_norm <- density(muestras_norm) # `density()` aplica el "suavizado"

# Convertimos la densidad en un "tibble" para manejarla más fácilmente 
densidad_normal <- tibble(
  x        = densidad_norm$x, # `x` == variable aleatoria
  densidad = densidad_norm$y
)

# Podemos representar la densidad gráficamente, junto con la curva normal:
densidad_normal |>
  mutate(dens_analitica = dnorm(x)) |>
  ggplot(aes(x, densidad)) +
  geom_line(color = color_defecto) +
  geom_line(aes(y = dens_analitica), color = PALETA[2])

# Obtenemos el valor de la moda:
estimador_map <- densidad_normal |> slice(which.max(densidad))
densidad_max  <- estimador_map |> pull(densidad)
moda          <- estimador_map |> pull(x)
```

El estimador MAP es `{r} moda`, siendo su densidad `{r} densidad_max`.

### Pregunta 10

-   Utilizando las muestras posteriores obtenidas en la pregunta 5, calcula los estimadores MAP para las dos clases, y compáralos con los que obtendrías con las fómulas analíticas.

::: {#respuesta-10 .callout-note}

```{r}
# Estimador MAP utilizando las muestras posteriores
map_clase_1 <- mean(muestras_precisas_clase_1)
map_clase_2 <- mean(muestras_precisas_clase_2)

# Estimador MAP analítico (media posterior) 
mu_post_1_analitico <- 234.81  # Según lo obtenido en la pregunta 5
mu_post_2_analitico <- 222.34  # Según lo obtenido en la pregunta 5

# Comparar los estimadores MAP con los valores analíticos
map_clase_1
map_clase_2
mu_post_1_analitico
mu_post_2_analitico

```


RESPUESTA 

ESTIMADORES MAP 
  Clase 1: 234.81
  Clase 2: 222.34
  
MU POST ANALÍTICO 
  Clase 1: 234.81
  Clase 2: 222.34
  
los resultados obtenidos son iguales en ambos casos. 

:::

# Ejercicio 2: Distribuciones Gamma

## Diferencia entre distribuciones

En el texto de @hoff2009 se utiliza una distribución Gamma en un ejemplo comparando las tasas de fertilidad de mujeres de 40 años con y sin título universitario, obtenido de la Encuesta Social General de los EEUU durante los años 1990 [puedes consultar los detalles en el capítulo 3 de @hoff2009].
Las distribuciones posteriores de la tasa de fertilidad de cada grupo son (p. .53):

$$
p(\theta_{sin} | y) = gamma(\theta_{sin}, 219, 112)
$$

$$
p(\theta_{con} | y) = gamma(\theta_{con}, 68, 45)
$$

La distribución Gamma está implementada en R mediante la familia de funciones `*gamma()`: `rgamma()`, `dgamma()`, `pgamma()`, y `qgamma()`.

### Pregunta 11

-   Utilizando un eje horizontal con precisión de .002, representa las dos distribuciones. Determina los límites del eje horizontal según tu propio criterio. Sin ver la forma de la función de densidad, ¿podrías deducir cuál habría de ser alguno de los dos límites del intervalo?

::: {#respuesta-11 .callout-note}
```{r}

# Parámetros de las distribuciones Gamma
shape_sin <- 219
scale_sin <- 112
shape_con <- 68
scale_con <- 45

# Determinar los límites del eje horizontal
x_min <- 0  # No tiene sentido valores negativos para estas distribuciones
x_max <- max(qgamma(0.999, shape_sin, scale_sin), qgamma(0.999, shape_con, scale_con))

# Generar un vector de valores para el eje horizontal con precisión de 0.002
x_vals <- seq(x_min, x_max, by = 0.002)

# Calcular las funciones de densidad para las distribuciones Gamma
y_sin <- dgamma(x_vals, shape_sin, scale_sin)
y_con <- dgamma(x_vals, shape_con, scale_con)

# Graficar las distribuciones Gamma
plot(x_vals, y_sin, type = "l", col = "blue", lwd = 2, 
     xlab = "Tasa de fertilidad", ylab = "Densidad", 
     main = "Distribuciones Gamma de tasa de fertilidad")
lines(x_vals, y_con, col = "red", lwd = 2)
legend("topright", legend = c("Sin título universitario", "Con título universitario"), 
       col = c("blue", "red"), lwd = 2)

```


RESPUESTA 

Alguno de los dos límites del intervalo debe ser en referencia a la media. El valor de la media debe encontrarse dentro de los límites y al saber que se sesga a la derecha hay que tomar en cuenta los valores del extremo superior. Así tomando en cuenta esto, los valores que deben estar son algun valor menor a 3060 (media de theta con) y algún valor superior a 24528 (media de theta sin). Así el límite superior podrías ser 25000.

:::

### Pregunta 12

-   Determina la probabilidad de que las mujeres de 40 años sin título universitario en los 90 en EEUU tuvieran una tasa de fertilidad superior a la de las mujeres con título universitario. Utiliza el método de Monte Carlo con 3 decimales de precisión al 99% de confianza, justificando el tamaño muestral elegido para aproximar las distribuciones posteriores (usa la media para justificar esta precisión). Si lo necesitas, revisa el material complementario del Tema 3 para determinar la varianza de la distribución Gamma.

::: {#respuesta-12 .callout-note}

```{r}
# Definir parámetros
n_muestras <- 18284  # Tamaño de la muestra

# Generar muestras para las dos distribuciones Gamma
muestras_sin_titulo <- rgamma(n_muestras, shape = 219, scale = 112)
muestras_con_titulo <- rgamma(n_muestras, shape = 68, scale = 45)

# Calcular la probabilidad de que las mujeres sin título tengan tasa de fertilidad superior
probabilidad_mc <- mean(muestras_sin_titulo > muestras_con_titulo)
probabilidad_mc
```

RESPUESTA 

probabilidad calculada: 1

Justificación tamaño muestral:

He elegido un tamaño muestral de 18,284 simulaciones. Este número sale al aplicar la fórmula del error estándar de Monte Carlo, usando la media aproximada de la distribución (𝜇= 24.528 y su varianza (𝜎2=1657.75).
Como el objetivo es tener una precisión de tres decimales, hay que asegurar que el error de la media simulada no supere 0.0005 veces la media. Al sustituir todo en la fórmula, da como resultado ese tamaño muestral. Así me aseguro de que la estimación de la media es lo bastante precisa para lo que pide el ejercicio.
:::

# Referencias
