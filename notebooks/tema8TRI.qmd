---
title: "tema8TRI"
format: html
---

Introducci√≥n

Este trabajo pretende aplicar el uso del an√°lisis bayesiano a la teor√≠a de respuesta al √≠tem. Para realizar esta aplicaci√≥n, se utilizan las respuestas a √≠tems del test PISA 2000. Los √≠tems de esta prueba eval√∫an la comprensi√≥n lectora a trav√©s de diversos formatos y grados de dificultad. El enfoque de la TRI ser√° el modelo de Rash o de 1PL y mediante este se estimar√°n par√°metros de dificultad por √≠tem y nivel de habilidad de cada estudiante. Sin embargo, en lugar de estimar un valor puntual por par√°metro, estimar√© una distribuci√≥n posterior. Adem√°s, para evaluar el ajuste del modelo, utilizar√© comprobaciones predictivas posteriores. 

Por tanto, para estimar la theta y dificultad, se utilizar√° el paquete brms de R que implementar√° m√©todos de muestreo de Markov Chain Monte Carlo para obtener distribuciones posteriores. Este m√©todo permitir√° obtener incertidumbre mediante intervalos cre√≠bles. 

Las distribuciones previas utilizadas son debilesmente informativas:para las habilidades de los estudiantes:ùúÉ‚àºùëÅ(0,1). Para las dificultades de los √≠tems: bj‚àºN(0,2). El modelo se estimar√° con 4 cadenas de meustreo, 2000 iteraciones por cadenas (1000 coomo warm-up), resultando en 4000 muestras posteriores del par√°metro.

Las posterior predictive checks se utizar√°n para comparar las respuestas observadas con datos simulados a partir de la distribuci√≥n posterior, para ver hasta qu√© punto el modelo es capaz de reproducir los patrones reales del conjunto de datos. 


```{r}

# Cargar paquetes necesarios

library(tidyverse)
library(dplyr)
library(readr)

library(here)
pisa <- read_csv2(here("dat", "PISA_2000 (2).csv"))

renv::snapshot()

# Seleccionar √≠tems (todos empiezan con "R")
items <- pisa %>% select(starts_with("R"))

# Verificar qu√© √≠tems tienen el valor 2
valores_por_item <- map(items, ~ unique(.x))
items_con_2 <- names(keep(valores_por_item, ~ 2 %in% .x))
items_solo_01 <- setdiff(names(items), items_con_2)

# Recodificar: √≠tems con 2 ‚Üí 2 = 1 (correcto); 0 y 1 = 0 (incorrecto/parcial)
#              √≠tems con solo 0 y 1 ‚Üí 1 = 1 (correcto); 0 = 0
items_binarios <- items %>%
  mutate(across(all_of(items_con_2), ~ ifelse(. == 2, 1,
                                       ifelse(. %in% c(0, 1), 0, NA)))) %>%
  mutate(across(all_of(items_solo_01), ~ ifelse(. == 1, 1,
                                         ifelse(. == 0, 0, NA))))

# Confirmar que hay 1s y 0s
summary(items_binarios)

#AHORA CALCULO EL MODELO 2PL

#PREPARAR EL ENTORNO

library(brms)

#TRANSFORMAR A FORMATO LARGO

# Agregar identificador de estudiante
items_binarios$id <- 1:nrow(items_binarios)

# Transformar a formato largo
data_long <- items_binarios %>%
  pivot_longer(
    cols = -id,
    names_to = "item",
    values_to = "response"
  ) %>%
  drop_na()  # Eliminar NA (no respuesta)

# Modelo log√≠stico con efectos aleatorios por √≠tem (dificultad) y por persona (habilidad)
modelo_2pl <- brm(
  response ~ 1 + (1 | id) + (1 | item),  # Rasgo latente por persona, dificultad por √≠tem
  data = data_long,
  family = bernoulli(link = "logit"),
  iter = 2000,
  chains = 4,
  cores = 4,
  seed = 123,
  control = list(adapt_delta = 0.95)
)


# Resumen de par√°metros estimados
summary(modelo_2pl)

# Graficar distribuciones posteriores
plot(modelo_2pl)

# Efectos por √≠tem (dificultad)
ranef(modelo_2pl)$item

# Efectos por persona (habilidad)
ranef(modelo_2pl)$id

summary(modelo_2pl)


```

```{r}
#ver dificultad de cada √≠tem
ranef(modelo_2pl)$item

#ver la habilida estimada de cada estudiante 
ranef(modelo_2pl)$id

```

```{r}
#posterior predictive check
pp_check(modelo_2pl)

```

Resultados:

Los estad√≠sticos de convergencia (Rhat = 1.00) y las muestras efectivas (ESS > 700 en todos los par√°metros) indican que el muestreo posterior fue adecuado.Adem√°s, las comprobaciones predictivas posteriores (pp_check) muestran una excelente correspondencia entre las respuestas observadas y las simuladas por el modelo. Por otro lado, se estim√≥ la habilidad de 1095 estudaintes (Œ∏), con media 0 y desviaci√≥n t√≠pica 1.29. Adem√°s, la dificultad de 26 √≠tems tuvo un rango de -2.67 (m√°s facil) y +1.28 (m√°s dificil). 

Ejemplo: 

√≠tem R088Q04T, con b -2.67 e intervalo del 95% 	[‚àí3.14, ‚àí2.17].

Respecto a la comprobaci√≥n predictiva posterior, Se utiliz√≥ la funci√≥n pp_check() para evaluar el ajuste del modelo. El gr√°fico de densidades muestra que las respuestas simuladas desde la posterior (l√≠neas claras) coinciden con la distribuci√≥n de las respuestas reales (l√≠nea oscura). Esto respalda la adecuaci√≥n del modelo 1PL a los datos observados.

En conclusi√≥n, el enfoque bayesiano aplicado al modelo 1PL de la Teor√≠a de Respuesta al √≠tem, ha permitido obtener estimaciones de habilidad y dificultad, junto con intervalos cre√≠bles que cuantifican la incertidumbre de forma clara. La evaluaci√≥n predictiva posterior sugiere un buen ajuste del modelo, lo que refuerza su utilidad para analizar √≠tems de comprensi√≥n lectora en evaluaciones educativas como PISA.


